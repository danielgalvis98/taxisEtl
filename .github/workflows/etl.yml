name: Run ETL Time Travel

on:
  workflow_dispatch:
    inputs:
      origen:
        description: "Origen desde donde se descargan los archivos"
        default: "https://d37ci6vzurychx.cloudfront.net/trip-data"
      archivos:
        description: "Archivos a ser procesados"
        default: "yellow_tripdata_2020-01.parquet,yellow_tripdata_2021-01.parquet,yellow_tripdata_2022-01.parquet"
      class:
        type: choice
        description: Clase java desde la que ejecuta el ETL
        options:
          - com.taxis.etl.travel_time.TravelTime
          - com.taxis.etl.payments_distance.PaymentsDistance
        default: com.taxis.etl.travel_time.TravelTime
      hilos:
        description: "Numero de hilos de procesador"
        default: "1"
      pi:
        description: "Spark Pi Program"
        default: "100"

env:
  TAXIS_ETL_FILES: ${{ github.event.inputs.archivos }}
  TAXIS_ETL_DOWNLOAD_FOLDER: downloads
  TAXIS_ETL_BASE_URL: ${{ github.event.inputs.origen }}
  TAXIS_ETL_DOWNLOAD_SOURCE: url

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout project sources
      uses: actions/checkout@v3
    - uses: actions/setup-python@v3
      with:
        python-version: '3.10'
    - name: Setup JDK
      uses: actions/setup-java@v3
      with:
        distribution: temurin
        java-version: '17'
    - uses: vemonet/setup-spark@v1
      with:
        spark-version: '3.1.2'
        hadoop-version: '2.7'
    - run: spark-submit --version
    - name: Run build with SBT
      run: sbt package
    - run: mkdir ./downloads
    - name: Run spark submit for ${{ github.event.inputs.class }}
      run: spark-submit --class ${{ github.event.inputs.class }} --master local[${{ github.event.inputs.hilos }}] "target/scala-2.12/taxis-etl_2.12-0.1.0.jar" ${{ github.event.inputs.pi }}
    - name: Archive ETL results
      uses: actions/upload-artifact@v3
      with:
        name: results
        path: results
